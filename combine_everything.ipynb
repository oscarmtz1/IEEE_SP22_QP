{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47de9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import json\n",
    "client_id = 'XXXX",
    "client_secret = 'XXXX",
    "redirect_uri='XXXX",
    "scope = 'user-read-currently-playing'\n",
    "\n",
    "token = spotipy.oauth2.SpotifyPKCE(client_id=client_id,redirect_uri=redirect_uri,scope=scope).get_access_token()\n",
    "spotify = spotipy.client.Spotify(auth=token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4573b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beneath the Mask - instrumental version'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_about_song = spotify.current_user_playing_track()\n",
    "data_about_song['item']['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c681209",
   "metadata": {},
   "source": [
    "Downloads currently playing song to myfile.mp3. This can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf05db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "songfile_destination = 'myfile.mp3'\n",
    "url = data_about_song['item']['preview_url']\n",
    "doc = requests.get(url)\n",
    "with open(songfile_destination, 'wb') as f:\n",
    "        f.write(doc.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32715b",
   "metadata": {},
   "source": [
    "Converts mp3 to wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc75225d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='soundfile/convertedfile.wav'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# files                                                                         \n",
    "src = \"myfile.mp3\"\n",
    "dst = \"soundfile/convertedfile.wav\"\n",
    "\n",
    "# convert wav to mp3                                                            \n",
    "sound = AudioSegment.from_mp3(src)\n",
    "sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f97caaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "\n",
      "---Now testing the model for one audio file---\n",
      "The model predicts: classical, but what was it actually? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "\n",
    "\n",
    "# Sampling rate.\n",
    "sr = 22050\n",
    "\n",
    "# Let's make sure all files have the same amount of samples and pick a duration right under 30 seconds.\n",
    "TOTAL_SAMPLES = 29 * sr\n",
    "\n",
    "# The dataset contains 999 files. Lets make it bigger. \n",
    "# X amount of slices => X times more training examples.\n",
    "NUM_SLICES = 10\n",
    "SAMPLES_PER_SLICE = int(TOTAL_SAMPLES / NUM_SLICES)\n",
    "\n",
    "NUM_SLICES = 10\n",
    "SAMPLES_PER_SLICE = int(TOTAL_SAMPLES / NUM_SLICES)\n",
    "\n",
    "def prepare_datasets(inputs, targets, split_size):\n",
    "    \n",
    "    # Creating a validation set and a test set.\n",
    "    inputs_train, inputs_val, targets_train, targets_val = train_test_split(inputs, targets, test_size=split_size)\n",
    "    inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs_train, targets_train, test_size=split_size)\n",
    "    \n",
    "    # Our CNN model expects 3D input shape.\n",
    "    inputs_train = inputs_train[..., np.newaxis]\n",
    "    inputs_val = inputs_val[..., np.newaxis]\n",
    "    inputs_test = inputs_test[..., np.newaxis]\n",
    "    \n",
    "    return inputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test\n",
    "\n",
    "def load_data(json_path):\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        #data = unicode(data, errors='replace')\n",
    "    f.close()\n",
    "\n",
    "    # Let's load our data into numpy arrays for TensorFlow compatibility.\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def preprocess_data(source_path, json_path):\n",
    "\n",
    "    # Let's create a dictionary of labels and processed data.\n",
    "    mydict = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "        }\n",
    "\n",
    "    # Let's browse each file, slice it and generate the 13 band mfcc for each slice.\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(source_path)):\n",
    "        for file in filenames:\n",
    "            # exclude a corrupted wav file that makes everything crash.\n",
    "            if os.path.join(dirpath, file) != 'data\\genres_original\\jazz\\jazz.00054.wav':\n",
    "                song, sr = librosa.load(os.path.join(dirpath, file), duration=29)\n",
    "                for s in range(NUM_SLICES):\n",
    "                    start_sample = SAMPLES_PER_SLICE * s\n",
    "                    end_sample = start_sample + SAMPLES_PER_SLICE\n",
    "                    mfcc = librosa.feature.mfcc(y=song[start_sample:end_sample], sr=sr, n_mfcc=13)\n",
    "                    mfcc = mfcc.T\n",
    "                    mydict[\"labels\"].append(i-1)\n",
    "                    mydict[\"mfcc\"].append(mfcc.tolist())\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # Let's write the dictionary in a json file.    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(mydict, f)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('mymodel')\n",
    "\n",
    "def tai_prediction(model, X, y, idx):\n",
    "    \n",
    "    genre_dict = {\n",
    "        0 : \"blues\",\n",
    "        1 : \"classical\",\n",
    "        2 : \"country\",\n",
    "        3 : \"disco\",\n",
    "        4 : \"hiphop\",\n",
    "        5 : \"jazz\",\n",
    "        6 : \"metal\",\n",
    "        7 : \"pop\",\n",
    "        8 : \"reggae\",\n",
    "        9 : \"rock\",\n",
    "        }\n",
    "        \n",
    "    predictions = model.predict(X)\n",
    "    genre = np.argmax(predictions[idx])\n",
    "    \n",
    "    #print(\"\\n---Now testing the model for one audio file---\\nThe model predicts: {}, and ground truth is: {}.\\n\".format(genre_dict[genre], genre_dict[y[idx]]))\n",
    "    print(\"\\n---Now testing the model for one audio file---\\nThe model predicts: {}, but what was it actually? \\n\".format(genre_dict[genre]))\n",
    "    return(genre_dict[genre])\n",
    "\n",
    "def super_prediction(path, target,num):\n",
    "    preprocess_data(source_path=path,json_path=target)\n",
    "    inputs, targets = load_data(json_path=target)\n",
    "\n",
    "    Xtrain, Xval, Xtest, ytrain, yval, ytest = prepare_datasets(inputs, targets, 0.2)\n",
    "    final_verdict = tai_prediction(model,Xtest,ytest, num)\n",
    "    return(final_verdict)\n",
    "\n",
    "music_file = 'soundfile'#sys.argv[0]\n",
    "music_target = 'data.json'#sys.argv[1]\n",
    "\n",
    "genre = super_prediction(music_file, music_target, 1)\n",
    "\n",
    "#inputs, targets = load_data(json_path=music_target)\n",
    "#stuff = train_test_split(inputs, targets, test_size=0.2)\n",
    "#model.predict(stuff[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d849e58",
   "metadata": {},
   "source": [
    "Predicts the genre of music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0877cb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "---Now testing the model for one audio file---\n",
      "The model predicts: rock, but what was it actually? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre = super_prediction(music_file, music_target, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f1acb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bro = spotify.recommendations(seed_genres={genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b146dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list = []\n",
    "uri_list = []\n",
    "for i in range(len(bro['tracks'])):\n",
    "    song_list.append(bro['tracks'][i]['name'])\n",
    "    uri_list.append(bro['tracks'][i]['uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "885d4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = 'user-modify-playback-state'\n",
    "token = spotipy.oauth2.SpotifyPKCE(client_id=client_id,redirect_uri=redirect_uri,scope=scope).get_access_token()\n",
    "spotify = spotipy.client.Spotify(auth=token)\n",
    "for uri in uri_list:\n",
    "    spotify.add_to_queue(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c09bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iron Man - 2012 - Remaster\n",
      "Run To You\n",
      "Pretty\n",
      "Africa\n",
      "Dr. Feelgood\n",
      "Rosanna\n",
      "Misery Business\n",
      "Go To War\n",
      "Ill Ray (The King)\n",
      "Found What I've Been Looking For\n",
      "Ziggy Stardust - 2012 Remaster\n",
      "What's My Age Again?\n",
      "Bullet With Butterfly Wings - Remastered 2012\n",
      "Enemies\n",
      "Warrior\n",
      "Alone\n",
      "Cryin'\n",
      "Red Flag\n",
      "Hearts On Fire\n",
      "Seven Nation Army\n"
     ]
    }
   ],
   "source": [
    "for song in song_list:\n",
    "    print(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e3129d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
